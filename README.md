# AI Virtual Companion System

<div align="center">

![AI Companion Banner](https://img.shields.io/badge/AI-Virtual%20Companion%20System-blue?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.11.12-green?style=for-the-badge)
![Flask](https://img.shields.io/badge/Flask-3.0.0-red?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)

**Intelligent Dialogue - Emotional Interaction**

An intelligent dialogue system based on large language models, supporting multiple personality states and dynamic emotional interaction

[Quick Start](#quick-start) â€¢ [Features](#features) â€¢ [Installation Guide](#installation-guide) â€¢ [User Documentation](#user-documentation) â€¢ [Development Guide](#development-guide)

</div>

## ğŸ“– Project Overview

The AI Virtual Companion System is an intelligent dialogue system based on Python, integrating advanced natural language processing technology and emotional interaction features. The project adopts a modular design, supporting multiple personality state switching and dynamic emotional expression, which can be customized according to user needs.

### ğŸŒŸ Core Features

- ğŸ¤– **Multi-model Support**: Integrates OpenAI, Claude, GLM and other large language models
- ğŸ­ **Personality System**: 5 different personality states, freely switchable
- â¤ï¸ **Emotional Levels**: 0-4 level dynamic emotional level adjustment
- ğŸ’¬ **Real-time Dialogue**: WebSocket-based real-time chat interface
- ğŸ§  **Smart Caching**: Dual guarantee of memory cache and persistent cache
- ğŸ¨ **Beautiful Interface**: Responsive web design, supports mobile devices
- âš™ï¸ **Flexible Configuration**: Fully configurable parameter system

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11.12+
- Anaconda/Miniconda (recommended) or Python virtual environment
- 4GB+ RAM

### One-click Installation

**Windows Users:**
```bash
# Run installation script
install.bat
```

**Linux/macOS Users:**
```bash
# Run installation script
chmod +x install.sh
./install.sh
```

### Manual Installation

1. **Create Environment**
```bash
# Using Conda (recommended)
conda env create -f environment.yml
conda activate ai-companion

# Or using Python virtual environment
python -m venv ai-companion-env
source ai-companion-env/bin/activate  # Linux/macOS
ai-companion-env\Scripts\activate     # Windows
```

2. **Install Dependencies**
```bash
pip install -r requirements.txt
```

3. **Configure Environment**
```bash
cp .env.example .env
# Edit the .env file to configure API keys and other parameters
```

4. **Start Service**
```bash
python start.py
```

### Access Application

After successful startup, visit the following addresses:

- **Home**: http://localhost:5000
- **Chat Interface**: http://localhost:5000/chat
- **API Status**: http://localhost:5000/api/status

## ğŸ¯ Features

### Personality System

| Personality State | Description | Characteristics |
|-------------------|-------------|------------------|
| **Gentle Mode** | Private mode, exclusive gentleness | Gentle, intimate, slightly dependent |
| **Elegant Mode** | Public mode, elegant and dignified | Elegant, polite, maintains distance |
| **Possessive Mode** | Dependent mode, strong possessiveness | Paranoid, possessive, strong attachment |
| **Tsundere Mode** | Tsundere mode, cold outside, warm inside | Stubborn, soft-hearted, says opposite of feelings |
| **Sweet Mode** | Sweet mode, completely immersed in love | Sweet, coquettish, full of love |

### Emotional Levels

- **Level 0**: Normal care
- **Level 1**: Slight concern, hoping for more attention
- **Level 2**: Gentle protection, proactive care and protection
- **Level 3**: Deep affection gaze, strong attachment
- **Level 4**: Complete attachment, hoping to completely possess you

## ğŸ“ Project Structure

```
core/
â”œâ”€â”€ ai_companion/             # Core package
â”‚   â”œâ”€â”€ ai/                   # AI modules
â”‚   â”‚   â”œâ”€â”€ persona_manager.py    # Personality manager
â”‚   â”‚   â””â”€â”€ conversation_manager.py # Conversation manager
â”‚   â”œâ”€â”€ services/             # Service layer
â”‚   â”‚   â”œâ”€â”€ llm_client.py         # LLM client
â”‚   â”‚   â””â”€â”€ cache_service.py       # Cache service
â”‚   â”œâ”€â”€ web/                  # Web application
â”‚   â”‚   â”œâ”€â”€ app.py               # Flask application
â”‚   â”‚   â””â”€â”€ socketio_handlers.py  # WebSocket handlers
â”‚   â”œâ”€â”€ config/               # Configuration management
â”‚   â”‚   â””â”€â”€ settings.py          # Configuration manager
â”‚   â””â”€â”€ utils/                # Utility modules
â”‚       â”œâ”€â”€ logger.py            # Logging configuration
â”‚       â”œâ”€â”€ helpers.py           # Helper functions
â”‚       â””â”€â”€ validators.py        # Validators
â”œâ”€â”€ web/                      # Web resources
â”‚   â”œâ”€â”€ templates/            # HTML templates
â”‚   â””â”€â”€ static/               # Static resources
â”œâ”€â”€ config/                   # Configuration files
â”œâ”€â”€ environment.yml           # Conda environment configuration
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ start.py                  # Startup script
â””â”€â”€ README.md                 # Project documentation
```

## âš™ï¸ Configuration

### Environment Variables

Configure the following parameters in the `.env` file:

```bash
# Application configuration
FLASK_APP=ai_companion.web.app:create_app
SECRET_KEY=your-secret-key-here

# Server configuration
HOST=0.0.0.0
PORT=5000
DEBUG=True

# LLM configuration
LLM_PROVIDER=openai
LLM_API_KEY=your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo
LLM_MAX_TOKENS=1000
LLM_TEMPERATURE=0.7
```

## ğŸš€ Deployment Guide

### Development Environment

```bash
python run.py --mode dev --debug
```

### Production Environment

```bash
# Using Gunicorn
gunicorn --worker-class eventlet -w 1 --bind 0.0.0.0:5000 start:app

# Or using script
python run.py --mode prod --host 0.0.0.0 --port 5000
```

## ğŸ”§ Troubleshooting

### Common Issues

**Q: Port occupied error on startup**
```bash
# Check port usage
netstat -tulpn | grep 5000
# Or use another port
python start.py --port 5001
```

**Q: LLM API call failed**
- Check if API key is correct
- Confirm network connection is normal
- Check log files for detailed error information

## ğŸ¤ Contributing

1. Fork the project
2. Create feature branch
3. Submit changes
4. Push to branch
5. Create Pull Request

## ğŸ“„ License

This project is licensed under the MIT License

## ğŸ™ Acknowledgments

- [OpenAI](https://openai.com/) - GPT model support
- [Anthropic](https://www.anthropic.com/) - Claude model support
- [Flask](https://flask.palletsprojects.com/) - Web framework
- [Socket.IO](https://socket.io/) - Real-time communication

---

<div align="center">

**If this project helps you, please give it a â­ï¸ to show your support!**

Made with â¤ï¸ by AI Companion Team

</div>